{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework for MRI reconstruction (Autumn 2019)\n",
    "\n",
    "In this tutorial, we provide the data loader to read and process the MRI data in order to ease the difficulty of training your network. By providing this, we hope you focus more on methodology development. Please feel free to change it to suit what you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction  ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL IMPORTS\n",
    "import h5py, os\n",
    "from functions import transforms as T\n",
    "from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "#cuda\n",
    "import torch.optim as optim\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu' #'cpu'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Unet model below created by MIT, and was used in this assignment as a platform to build the neural network. https://github.com/facebookresearch/fastMRI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNET MODEL\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        return self.layers(input)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
    "            f'drop_prob={self.drop_prob})'\n",
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "\n",
    "    This is based on:\n",
    "        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "        for biomedical image segmentation. In International Conference on Medical image\n",
    "        computing and computer-assisted intervention, pages 234–241. Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "            chans (int): Number of output channels of the first convolution layer.\n",
    "            num_pool_layers (int): Number of down-sampling and up-sampling layers.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch, drop_prob)\n",
    "\n",
    "        self.up_sample_layers = nn.ModuleList()\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
    "            ch //= 2\n",
    "        self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
    "            nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = input\n",
    "        # Apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.max_pool2d(output, kernel_size=2)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Apply up-sampling layers\n",
    "        for layer in self.up_sample_layers:\n",
    "            output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            output = torch.cat([output, stack.pop()], dim=1)\n",
    "            output = layer(output)\n",
    "        return self.conv2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######This function was amended to allow for changes in the batch size.######\n",
    "\n",
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "    \n",
    "    ######### AMENDMENT #########\n",
    "    \n",
    "    #convert complex numbers to abs to ensure it is useable.\n",
    "    #Cropping was completed here to allow for images to be \n",
    "    #compared effectively and can be placed over eachother 320 by 320 square\n",
    "    \n",
    "    volume_image_abs = T.complex_abs(img_gt) \n",
    "    cropped_gt = T.center_crop(volume_image_abs, [320, 320])\n",
    "    cropped_gt = cropped_gt\n",
    "        \n",
    "    volume_image_abs = T.complex_abs(img_und) \n",
    "    cropped_img_und = T.center_crop(volume_image_abs, [320, 320])\n",
    "    cropped_img_und = cropped_img_und\n",
    "        \n",
    "    return cropped_gt,cropped_img_und, norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-defined ultily functions used in creating the neural net\n",
    "\n",
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list\n",
    "        self.acceleration = acceleration\n",
    "        self.center_fraction = center_fraction\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)\n",
    "    \n",
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "\n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "\n",
    "        which_data_path = data_path[i]\n",
    "\n",
    "        for fname in sorted(os.listdir(which_data_path)):\n",
    "\n",
    "            subject_data_path = os.path.join(which_data_path, fname)\n",
    "\n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "\n",
    "            with h5py.File(subject_data_path, 'r') as data:\n",
    "                num_slice = data['kspace'].shape[0]\n",
    "\n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "\n",
    "    return data_list  \n",
    "   \n",
    "    \n",
    "from skimage.measure import compare_ssim  \n",
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    return compare_ssim(\n",
    "        gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max()\n",
    "    )  \n",
    "\n",
    "\n",
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is where the model is created. ####Describe each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model = UnetModel(\n",
    "    in_chans = 1,\n",
    "    out_chans = 1,\n",
    "    chans = 32,\n",
    "    num_pool_layers = 4,\n",
    "    drop_prob = 0 ).to(device) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The data set is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set initial path for the fullset of training data\n",
    "file_path = '/data/local/NC2019MRI/train'\n",
    "\n",
    "# Shuffle sets, and split train_index into train and validation 80:20 respectively. \n",
    "#this was chosen as a reasonable split for the data set size. Any less the validation results \n",
    "#may prove unrepresentative, whereas any more would deprive the model of useful information to train with\n",
    "\n",
    "#Shuffling was done to ensure higher probabilty that the neural model will be trained in such as way,\n",
    "# that it will generalize over unseen data sets.\n",
    "numfiles_all = len(os.listdir(file_path))\n",
    "print (numfiles_all)\n",
    "indx = np.arange(numfiles_all)\n",
    "np.random.shuffle(indx)\n",
    "\n",
    "split_80_20 = 0.8 * numfiles_all\n",
    "split_80_20 = int(split_80_20)\n",
    "print(split_80_20)\n",
    "\n",
    "#############\n",
    "np.random.seed(42)\n",
    "\n",
    "train_inx = indx[:split_80_20]\n",
    "val_inx = indx[split_80_20:]\n",
    "\n",
    "#varify split and shuffling\n",
    "print(\"train_inx\",train_inx)\n",
    "print(\"val_inx\",val_inx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #set list for storage of both train and validation data\n",
    "    train_data_list = {}\n",
    "    train_data_list['val']= [0] * len(val_inx)\n",
    "    train_data_list['train'] = [0] * len(train_inx)\n",
    "    count = 0  \n",
    "    \n",
    "    #read in and store the h5 files from the data set in the coorect order as in the shuffed indexes\n",
    "    #for each set\n",
    "    for fname in sorted(os.listdir(file_path)): \n",
    "        subject_path = os.path.join(file_path, fname)\n",
    "        with h5py.File(subject_path,  \"r\") as hf:\n",
    "             total_num_slices = hf['kspace'].shape[0]\n",
    "\n",
    "        #for train data      \n",
    "        for i in range(len(train_inx)):\n",
    "            if (train_inx[i] == count):\n",
    "                train_data_list['train'][i] = (file_path+ \"/\" +fname, fname, total_num_slices)  \n",
    "                break\n",
    "        #for validation data   \n",
    "        for k in range(len(val_inx)):\n",
    "            if (val_inx[k] == count):\n",
    "                train_data_list['val'][k] = (file_path+ \"/\"+ fname, fname, total_num_slices)\n",
    "                break\n",
    "        count = count +1\n",
    "\n",
    "            \n",
    "    train_data_final ={}         \n",
    "    train_data_final['train'] = []  \n",
    "    train_data_final['val'] = []  \n",
    "    \n",
    "    #The previous function only shuffled the H5files but did not include the slices. The slices are included\n",
    "    #in the correct order here for both train and validation\n",
    "    for i in range (len(train_data_list['train'])):\n",
    "        for slice in range (5,train_data_list['train'][i][2]):\n",
    "            train_data_final['train'].append((train_data_list['train'][i][1], train_data_list['train'][i][0], (slice)))\n",
    "        \n",
    "\n",
    "    for i in range (len(train_data_list['val'])):\n",
    "        for slice in range (5,train_data_list['val'][i][2]):\n",
    "            train_data_final['val'].append((train_data_list['val'][i][1], train_data_list['val'][i][0], slice))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Varification of shuffled data lists for loading\n",
    "print(\"VALIDATION SET\")\n",
    "valcount = 0\n",
    "for i in range (len(train_data_final['val'])):\n",
    "    print(\" count : \",valcount,\"  \", train_data_final['val'][i])\n",
    "    valcount = valcount + 1\n",
    "    \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "train_count = 0    \n",
    "print(\"TRAIN SET\")\n",
    "for i in range (len(train_data_final['train'])):\n",
    "    print(\" count : \",train_count,\"  \", train_data_final['train'][i])\n",
    "    train_count = train_count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_path_train = '/data/local/NC2019MRI/train'\n",
    "    data_path_val = '/data/local/NC2019MRI/train'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0428293723e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMRIDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceleration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcen_fract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_final' is not defined"
     ]
    }
   ],
   "source": [
    "#loads_train_data\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #This is where the undersampling parameters are set. In this ###################\n",
    "    acc = 8\n",
    "    cen_fract = 0.04\n",
    "    seed = False # random masks for each slice \n",
    "    \n",
    "    #More works the better.....############\n",
    "    num_workers = 12 \n",
    "    \n",
    "    \n",
    "    #Train\n",
    "    train_dataset = MRIDataset(train_data_final['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=5, num_workers=num_workers) \n",
    "    \n",
    "    # Validation: turned off in final models, used in experimetaly \n",
    "    validation_dataset = MRIDataset(train_data_final['val'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    validation_loader = DataLoader(validation_dataset, shuffle=True, batch_size=5, num_workers=num_workers)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here is where the neural network model was trained. The parameters and their values present below was that of the best overall results, however is is noteworthy that validation was turned off in final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELOLOOO\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73a8e88d6667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# # We use mean square error (MSELoss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Optimisers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#set training\n",
    "%matplotlib inline \n",
    "\n",
    "# set learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "#set number of epoches, i.e., number of times we iterate through the training set\n",
    "epoches = 50\n",
    "\n",
    "#We use mean square error (MSELoss) a base parameter.\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# Optimisers a variable parameter that was experimented with\n",
    "optimiser = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "#Lists for plotting val/train SSIM/Loss/prEpoch\n",
    "train_av_epoch_ssim_list = []\n",
    "train_av_epoch_loss_list = []\n",
    "\n",
    "val_av_epoch_ssim_list = []\n",
    "val_av_epoch_loss_list = []\n",
    "\n",
    "epoch_count = 0\n",
    "\n",
    "#Model training\n",
    "for epoch in range(epoches):\n",
    "    \n",
    "    # Set the model to training mode.\n",
    "    model.train()\n",
    "    \n",
    "    #For generating average calculation for each epoch of SSIM and Loss\n",
    "    train_total_loss = 0\n",
    "    train_total_ssim = 0\n",
    "    train_iterations= 0\n",
    "    \n",
    "    val_total_loss = 0\n",
    "    val_total_ssim = 0\n",
    "    val_iterations= 0\n",
    "    \n",
    "    #Training\n",
    "    for data in train_loader:\n",
    "\n",
    "        #The cropped ground truth target and the undersampled input are unloaded\n",
    "        #here for use in generation of our prediction.\n",
    "        img_gt, img_und, _ = data\n",
    "        \n",
    "        #pushed to the GPU\n",
    "        img_gt = img_gt.to(device) \n",
    "        img_und.to(device) \n",
    "        \n",
    "        #zeros the gradient #######\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        #Reconstruction/prediction from undersampled data\n",
    "        y_pred = model(img_und.to(device))\n",
    "        \n",
    "        #In order for to calculate SSIM and to visualise the images,\n",
    "        #the data must be taken back off the GPU, and converted to a numpy array\n",
    "        #from a tensor object.\n",
    "        A = img_und.squeeze().squeeze().numpy()[0:1,:,:]\n",
    "        B = y_pred.squeeze().squeeze().squeeze(0).detach().cpu()\n",
    "        B = y_pred.squeeze().data.cpu().numpy()\n",
    "        B = B[0:1, :, :]\n",
    "        C = img_gt.squeeze().squeeze().squeeze(0).cpu().numpy()[0:1,:,:]\n",
    "        \n",
    "    \n",
    "\n",
    "        #Visualise results. Every 10 iterations all three data set images\n",
    "        #are displayed for visual comparision. This is a useful tool for \n",
    "        #watching the progress of the training, and to identify any potential errors\n",
    "        #at an early stage. This is because a percieved good SSIM value and low loss\n",
    "        #does not neccessarily translate to an accurate image from practice.\n",
    "        \n",
    "        #Concatenates all the data\n",
    "        all_imgs = np.concatenate([A,B,C], axis=0)\n",
    "        \n",
    "        # 0 = UNDERSAMPLED. 1 = PREDICTION. 2 = GROUND_TRUTH\n",
    "        #if train_iterations % 10 == 1:\n",
    "            #show_slices(all_imgs, [0,1,2], cmap='gray')\n",
    "            #plt.pause(1)\n",
    "\n",
    "        \n",
    "        #calculate the loss from training data\n",
    "        loss = loss_fn(img_gt.to(device), y_pred)\n",
    "        loss.backward() \n",
    "        optimiser.step()\n",
    "        \n",
    "        #calculate total loss for epoch to generate average loss\n",
    "        train_total_loss = train_total_loss + loss.item()\n",
    "        \n",
    "        # calculate total ssim value for epoch to generate average ssim\n",
    "        ssim_value = ssim(C,B)\n",
    "        train_total_ssim = train_total_ssim + ssim_value\n",
    "     \n",
    "\n",
    "        #count\n",
    "        train_iterations = train_iterations +1\n",
    "        \n",
    "    #Calculate average train SSIM value and Loss values per epoch    \n",
    "    train_av_ssim = train_total_ssim/train_iterations\n",
    "    train_av_loss = train_total_loss/train_iterations\n",
    "    \n",
    "    train_av_epoch_ssim_list.append(train_av_ssim)\n",
    "    train_av_epoch_loss_list.append(train_av_loss)\n",
    "    \n",
    "    \n",
    "    #Validation: After each epoch the validation is conducted on the model on the validation set. \n",
    "    #In the final models all validation is turned off, and the full training data set was used for reasons \n",
    "    #discussed in experiements section.\n",
    "    \n",
    "    \n",
    "    #Set to no grad, as back propogation is not requried in evalution/validation of model #############\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #Set to evaluation mode. This is because it is important the model does not\n",
    "        #see this data, as it would invalidate its purpose. Described in report in more detail.\n",
    "        model.eval()\n",
    "        for data in validation_loader:\n",
    "\n",
    "            #from data loader\n",
    "            img_gt, img_und, _ = data\n",
    "            \n",
    "            #Reconstruction/prediction from undersampled data\n",
    "            img_gt = img_gt.to(device) \n",
    "            img_und.to(device) \n",
    "            optimiser.zero_grad()\n",
    "            y_pred = model(img_und.to(device))\n",
    "            \n",
    "            #As in training step\n",
    "            A = img_und.squeeze().squeeze().numpy()[0:1,:,:]\n",
    "            B = y_pred.squeeze().squeeze().squeeze(0).detach().cpu()\n",
    "            B = y_pred.squeeze().data.cpu().numpy()\n",
    "            B = B[0:1, :, :]\n",
    "            C = img_gt.squeeze().squeeze().squeeze(0).cpu().numpy()[0:1,:,:]\n",
    "            \n",
    "            #calculate the loss from validation data\n",
    "            val_loss = loss_fn(img_gt.to(device), y_pred)\n",
    "            optimiser.step()\n",
    "            \n",
    "            #calculate total loss for epoch to generate average loss\n",
    "            val_total_loss = val_total_loss + loss.item()\n",
    "        \n",
    "            #calculate total ssim value for epoch to generate average ssim\n",
    "            ssim_value = ssim(C,B)\n",
    "            val_total_ssim = val_total_ssim + ssim_value\n",
    "            \n",
    "            #count\n",
    "            val_iterations = val_iterations + 1\n",
    "    \n",
    "        #Calculate average validation SSIM value and Loss values per epoch\n",
    "        val_av_ssim = val_total_ssim/val_iterations\n",
    "        val_av_loss = val_total_loss/val_iterations\n",
    "    \n",
    "        #Store in list for graphing\n",
    "        val_av_epoch_ssim_list.append(val_av_ssim)\n",
    "        val_av_epoch_loss_list.append(val_av_loss)\n",
    "    \n",
    "    #For visualizing progress\n",
    "    epoch_count = epoch_count + 1\n",
    "    print(\"epoch_count \", epoch_count)\n",
    "\n",
    "    #Varification of lists\n",
    "print(\"epoch: \", epoch_count,\"train_av_epoch_ssim_list :\", train_av_epoch_ssim_list)\n",
    "print(\"epoch: \", epoch_count,\"train_av_epoch_loss_list :\", train_av_epoch_loss_list)\n",
    "print(\"epoch: \", epoch_count,\"val_av_epoch_ssim_list :\", val_av_epoch_ssim_list)\n",
    "print(\"epoch: \", epoch_count,\"val_av_epoch_loss_list :\", val_av_epoch_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION VS TRAINING SSIM COMPARISON\n",
    "plt.plot(range(len(train_av_epoch_ssim_list)), train_av_epoch_ssim_list,'r', label = \"Av Train SSIM\")\n",
    "plt.plot(range(len(val_av_epoch_ssim_list)), val_av_epoch_ssim_list,'b', label = \"Av Val SSIM\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Av SSIM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION VS TRAINING LOSS COMPARISON\n",
    "plt.plot(range(len(train_av_epoch_loss_list)), train_av_epoch_loss_list,'r', label = \"Av Training loss\")\n",
    "plt.plot(range(len(val_av_epoch_loss_list)), val_av_epoch_loss_list,'b', label = \"Av Val loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"unet_model_save_50ep_sgd_le1_b5_L1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates averages for entire model as an approximate meas\n",
    "\n",
    "#x = train_av_epoch_loss_list\n",
    "#x = val_av_epoch_loss_list\n",
    "#x = train_av_epoch_ssim_list\n",
    "x = val_av_epoch_ssim_list\n",
    "\n",
    "total = 0\n",
    "for i in range(len(x)):\n",
    "    total = total +x[i]\n",
    "    av = total/(len(x))\n",
    "print(av)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The body is comprised of matter which possess natural magnetic properties. These properties are utilized using a combination of magnetic disruption and radio waves to produce KData.https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121941/\n",
    "\n",
    "KData in itself is not useful for visualising biological features , however when an inverse discrete fourier transform (DFT) is applied to the data, the data can be visualized.\n",
    "KData contains complex numbers, therefore it must be preprocessed before visualization can occur (complex numbers made absolute). KData is held within 3 dimensions and is comprised of voxels. Each voxel contains a partition of the total kdata.\n",
    "A common problem for producing accurate Kdata is the long acquisition time, which converts to higher financial costs in healthcare and inefficiency . By using a low acquisition time, the end result is less accurate. However by applying a neural network model, the image can be accurately predicted. https://www.frontiersin.org/articles/10.3389/fnins.2018.00777/full\n",
    "\n",
    "In this task, two sets of data were provided, each containing kdata.h5 files. Each H5 file contains multiple slices, which are stacked to form a 3D object.  In the test set, there were 30 low acquisition(low accuracy) H5 files, and in the training set were 70 h5 files each contain high acquisition (high accuracy). \n",
    "The original H5 files of the training set used as a ground truth, and were the control of the experiment, and acted as the target output result implemented in the neural network designed.\n",
    "Two secondary data sets were created from undersampling the original training data, one 8-fold(high undersampled, and inaccurate), and one 4-fold(less undersampled).\n",
    "\n",
    "The undersampled was created by applying ‘masks’ to the original ground truth data, which essential removed some Kdata information, and in doing so mimicked a low acquisition data MRI scan.\n",
    "The aim of the experiment was to generate 2 neural network models using both of these undersampled sets with original target set, which can accurately convert low acquisition images to a more accurate representation, resembling that of the original ground truth set. \n",
    "\n",
    "# what is SSIM, and how was it used  #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design\n",
    "\n",
    "## Data set\n",
    "\n",
    "Training data is used to train our model and determine the parameters of the model to achieve the best results. But in the training process, when the bias of the data set is too high, it will cause the model we trained produce overfitting.  \n",
    "\n",
    "Due to the role of fitting the high-frequency noise elements, large amplitudes appear when higher-order sessions accompany. In this case, the high order polynomial courses will generate the corresponding high-frequency fluctuations required.\n",
    "\n",
    "#\n",
    "However,  it can ignore each other out at the data points to achieve the exact fit data points.\n",
    "#\n",
    "\n",
    "This leads to the large deviations we see between the sampled points. This is known as overfitting which is a constant dilemma when working with the noisy datasets or a complex model. A model that overfits its training data tends to be able to generalise to unseen data and is not helpful in the process of machine learning.\n",
    "\n",
    "To solve this problem, validatation of the data is required to ensure that the model we perceive is the optimal one. In our design, we divide the training data set into 80% training data and 20% validation data. After training the model with training data, we use the validation data set to test all models and then select the model with the least error rate. After formulating the optimal model, we then use the test data set to test the generalized ability of the trained model.\n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "### U-net\n",
    "\n",
    "![unet.png](./unet.png)\n",
    "In 2015, Olaf Ronneberger and others proposed a U-net network structure. The U-net network is a semantic segmentation network based on FCN, which is suitable for medical image segmentation.\n",
    "\n",
    "\n",
    "The entire U-Net network structure is shown in the figure above, similar to a large U letter: first convolution + Pooling down-sampling; then deconvolution for up-sampling, low-level feature map before the crop, and fusion; then up-sampling again. This process is repeated until a feature map is generated with an output of 388x388x2, and then finally obtain the output segment map through soft-max. Overall, it is very similar to the FCN idea. Unet's original intention is to solve the problems of biomedical images. This gave rise to it being widely used in various directions of semantic segmentation, such as satellite image segmentation and industrial defect detection.\n",
    "[Ronneberger O, Fischer P, Brox T, U-net: Convolutional networks for biomedical image segmentation. International Conference on Medical image computing and computer-assisted intervention, 2015 ]\n",
    "\n",
    "[Wenjun Y, Yuanyuan W, Shengjia G, The Domain Shift Problem of Medical Image Segmentation and Vendor-Adaptation by Unet-GAN. International Conference on Medical Image Computing and Computer-Assisted Intervention, 2019 ]\n",
    "\n",
    "###### Advantages\n",
    "\n",
    "• Support for training models with a small amount of data \n",
    "\n",
    "• Get higher segmentation accuracy by classifying each pixel \n",
    "\n",
    "• Fast segmentation with trained models \n",
    "\n",
    "\n",
    "### Gan\n",
    "\n",
    "GAN was another consideration when researching a base model for the network. It is composed of a generator and a discriminator. The purpose of the generator is to generate fake targets in an attempt to completely deceive the discriminator. The discriminator improves its discrimination ability by learning the true target and the false target, so as not to let the false target fool itself. The two evolved and played against each other. One side evolved and the other lost. Finally, the evolution stopped until the false target was very similar to the true target. The main flow is similar to the figure above. First of all, there is a generation generator that can generate some very poor pictures, and then there is a generation discriminator that can accurately classify the generated picture with the real picture, and then repeat the above action(If not necessary, delete them) Compared with all other models, GAN can produce clearer and true samples. GAN uses an unsupervised learning method for training, which can be widely used in the fields of unsupervised learning and semi-supervised learning. However, because of the unsupervised GAN, in the generation process, it will generate some weird pictures according to its own wishes for a long time. What’s worse, this picture can still get a high score.\n",
    "\n",
    "[ Sebastian N, Botond C, Ryota T, f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization.  Advances in Neural Information Processing Systems, 2016 ]\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In this experiment, we chose U-net as our training model due to we have seen that U-net has achieved good results in this field in many previous studies, while GAN has fewer applications in medical imaging. Also, U-net has a fast processing speed and a higher segmentation accuracy which is beneficial to our experiment.\n",
    "\n",
    "# Batch Size \n",
    "\n",
    "Batch size is the number of samples selected for a single training session. Its size affects the degree and speed of optimization of the model. At the same time, it directly affects the GPU memory usage. When chose the best batch size, it can improve memory utilization through parallelization by enabling the GPU to run at full capacity to improve training speed. \n",
    "\n",
    "\n",
    "#Also, the number of iterations of a single epoch is reduced and the adjustment of parameters is slow, which more epochs are required to achieve the same recognition accuracy.#\n",
    "\n",
    "Most importantly, the optimimum batch size for a particular model will improve the gradient descent.\n",
    "[ Alfredo C, Adam P, Eugenio C, An Analysis of Deep Neural Network Models for Practical Applications. arXiv preprint arXiv:1605.07678, 2016]\n",
    "\n",
    "# Learning Rate\n",
    "\n",
    "The learning rate determines how far the weights move in the gradient direction in a batch. Choosing a suitable learning rate requires constant experimentation and adjustment.\n",
    "\n",
    "When the learning rate is very small, the training will become reliable, that is, the gradient will gradually approach the minimum value. The calculated loss value will become smaller as well as the cost is that the training process will take longer. When the learning rate is very large, the training process will ignore the minimum value, showing that the loss value continuously fluctuates. In the most severe cases, it may never reach the minimum value, or even jump out of this range and fall into another sinking area. [ Robert A.Jacobs Increased rates of convergence through learning rate adaptation. Neural Networks, 1988]\n",
    "\n",
    "The learning rate determines how far the weights move in the gradient direction in a batch. Choosing a suitable learning rate requires constant experimentation and adjustment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "\n",
    "\n",
    "RMSprop\n",
    "\n",
    "For the learning rate of models, traditional optimizer either set the learning rate to a constant or adjust the learning rate based training results. All ignore the potential of the learning rate.\n",
    "\n",
    "We can consider RMSprop as an adaptation of the rprop algorithm to learning with mini-batch. This was the original motivation for developing the algorithm. It performs low learning rates on parameters related to frequently occurring features and performs high learning rates to obtain parameters related to less commonly used features. Therefore, it is very suitable for dealing with sparse data. In this way, it can greatly improve the robustness of SGD and solve the problem of the sharp drop in learning rate. It is assumed that during the 𝑡\n",
    "\n",
    "iteration, each formula is as follows:\n",
    "\n",
    "[Geoffrey Hinton Neural Networks for machine learning nline course. https://www.coursera.org/learn/neural-networks/home/welcome]\n",
    "\n",
    "𝑠𝑑𝑤=𝛽𝑠𝑑𝑤+(1−𝛽)𝑑𝑊2𝑠𝑑𝑏=𝛽𝑠𝑑𝑏+(1−𝛽)𝑑𝑏2𝑊=𝑊−𝛼𝑑𝑊𝑠𝑑𝑤⎯⎯⎯⎯⎯⎯√+𝜀𝑏=𝑏−𝛼𝑑𝑏𝑠𝑑𝑤⎯⎯⎯⎯⎯⎯√+𝜀\n",
    "\n",
    "In the above formula, 𝑠𝑑𝑤\n",
    "and 𝑠𝑑𝑏 are the gradient momentum accumulated by the loss function during the first 𝑡−1 iterations,.Respectively, 𝛽 is an index of gradient accumulation. In order to prevent the denominator from being zero, a very small value 𝜀\n",
    "\n",
    "is used for smoothing which generally take 1e-8.\n",
    "\n",
    "The RMSprop algorithm calculates the differential squared weighted average of the gradient. This method is beneficial to eliminate the direction of large swing amplitude and is used to correct the swing amplitude so that the swing amplitude in each dimension is smaller. On the other hand, it also makes the network function converge faster.\n",
    "\n",
    "\n",
    "\n",
    "Adaptive Moment Estimation (Adam)\n",
    "\n",
    "Adaptive Moment Estimation (Adam) is a method that computes adaptive learning rates for each parameter. In addition to collecting past squared gradients' exponentially decaying average 𝑣𝑡\n",
    ", Adam also keeps an exponentially decaying average of past gradients 𝑚𝑡 which similar to momentum. In this way, it can flat minima in the error surface. We compute the 𝑣𝑡 and 𝑚𝑡\n",
    "\n",
    "as follows: [Bottou, L, The Tradeoffs of Large Scale Learning. Optimization for Machine Learning, 2012]\n",
    "\n",
    "𝑚𝑡=𝛽1𝑚𝑡−1+(1−𝛽1)𝑔𝑡𝑣𝑡=𝛽2𝑣𝑡−1+(1−𝛽2)𝑔2𝑡\n",
    "\n",
    "If 𝑚𝑡\n",
    "and 𝑣𝑡 are initialized as zero vectors, they will be biased towards 0, so a bias correction appear. It can offset these deviations by calculating the updated 𝑚𝑡 and 𝑣𝑡\n",
    "\n",
    "as follows:\n",
    "\n",
    "𝑚̂ 𝑡=𝑚𝑡1−𝛽𝑡1𝑣̂ 𝑡=𝑣𝑡1−𝛽𝑡2\n",
    "\n",
    "and last upated Adam is:\n",
    "\n",
    "𝜃𝑡+1=𝜃𝑡−𝜂𝑣̂ 𝑡⎯⎯⎯√+𝜀𝑚̂ 𝑡\n",
    "\n",
    "where 𝛽1\n",
    "and 𝛽2 is often to set close to 1\n",
    "\n",
    "Adam is generally considered to be quite robust in the choice of hyperparameters, although the learning rate sometimes needs to be modified to default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANAYLSIS\n",
    "\n",
    "Learning Rate\n",
    "\n",
    "\n",
    "We calculated the average loss value and SSIM of training data set with the batch size of 5 and epochs is 50. The following figures are the examples of the average loss value of different learning rate. The average loss value drops rapidly around the first five epochs, and then it tends to decrease steadily. When enhancing the learning rate from 1e-1 to 1e-5, the loss value in of the same epoch increases, and its overall trend remains unchanged. \n",
    "![LR1Loss.png](./LR1Loss.png)\n",
    "![LR4Loss.png](./LR4Loss.png)\n",
    "\n",
    "\n",
    "The following are the results of average SSIM. It can be seen from the figures that average SSIM increased rapidly around the first five epochs, followed by an upward trend, and accompanied by fluctuations of a certain intensity. When learning rate increasing, the subsequent fluctuation of the SSIM value weakened, and the results obtained gradually became more stable.\n",
    "![LR1SSIM.png](./LR1SSIM.png)\n",
    "![LR4SSIM.png](./LR4SSIM.png)\n",
    "\n",
    "\n",
    "The following table is a summary of the results of the above. In the obtained results, the learning rate of 1e-1 to le-4 all conform to the above analysis, but the hyperparameter of 1e-5 do not correspond to the above rule. This is because after the learning rate increases, if epoch keeps at the same value, then the number of samples received is not enough to reflect the overall changing trend of average loss value and average SSIM.\n",
    "\n",
    "|    Learning Rate    | Average Training Data Loss   | Average Training Data SSIM |\n",
    "| ---------- | --- | --- |\n",
    "| 1e-1 |  0.00825| 0.47871| \n",
    "| 1e-2 |  0.00808| 0.48208| \n",
    "| 1e-3 |  0.01674| 0.35583|\n",
    "| 1e-4 |  0.03098| 0.22719|\n",
    "| 1e-5 |  0.01797| 0.10929|\n",
    "\n",
    "![LR5Loss.png](./LR5Loss.png)\n",
    "![LR5SSIM.png](./LR5SSIM.png)\n",
    "\n",
    "The above analysis all based on 4-folders, we calculated with 8 times acceleration rate. We change the epoch to 120 and the learning rate is le-1 to achieve a better result. The leaning of the two values is almost the same as that in the case of 4-folders, except that the fluctuation of SSIM is slightly more obvious due to the increase of epoch. From the table below, its average loss is more miniature and the average SSIM is higher.\n",
    "\n",
    "|    Acceleration Rate    | Average Training Data Loss Value   | Average Training Data SSIM |\n",
    "| ---------- | --- | --- |\n",
    "| 4 times |  0.00825| 0.47871| \n",
    "| 8 times |  0.00437| 0.59028| \n",
    "\n",
    "\n",
    "\n",
    "We calculated the average SSIM obtained after the data set uses RMSprop with 50 epochs and displayed in the figure below. It can be seen from the figure that the data used in our training fluctuates rigorously and the result is not clear, so we do not use RMSprop in this experiment.\n",
    "\n",
    "\n",
    "We calculated the average loss value and SSIM of both training data and validation data set with the batch from 3 to 6 when epochs is 0 to 50. We can easily conclude from the table that the SSIM and is better when the Batch is 5 as we list the result as below.\n",
    "\n",
    "|    Batch Size    | Average Training Data Loss Value  |    Average Validation Data Loss Value   | Average Training Data SSIM |    Average Validation Data SSIM    |\n",
    "| ---------- | --- | --- | --- | --- |\n",
    "| 3 |  0.00816| 0.00859| 0.47535 | 0.50365|\n",
    "| 4 |  0.00808| 0.00784| 0.48208 | 0.45985|\n",
    "| 5 |  0.00891| 0.00913| 0.45697 | 0.53715|\n",
    "| 6 |  0.00872| 0.00890| 0.46395 | 0.49930|\n",
    "\n",
    "When the batch is 5, the obtained data curve is shown below. Both the average SSIM and the SSIM at 50 epochs of the training data set is around 0.46. Since the SSIM of validation data set is more vibrate and with an average of 0.53 but can reach about 0.57 at 50 epochs, which is significant. \n",
    "\n",
    "As for the training data's loss value, statistics tend to descend steadily. Although validation data loss contains a lot of noise, the overall trend is still decreasing.\n",
    "\n",
    "![Batch5Loss.png](./Batch5Loss.png)\n",
    "![Batch5SSIM.png](./Batch5SSIM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    " The predicted value obtained after using the model for training in the neural network needs to be compared with the ground truth so that the model can self-corrects until the difference becomes really small. With different loss functions, the influence on the model will differ too. We need to choose the most suitable function to get the most ideal model. We decided to use L1 as the orimary loss functions as: \n",
    "\n",
    "#### L1 Loss\n",
    "\n",
    "$${\n",
    "  loss(x,y)= \\sum_{i=1}^{n} (x-y)^2 \n",
    " }$$\n",
    "\n",
    "L1 Loss Function is used to minimize the error which is the sum of the all the absolute differences between the true value $x$ and the predicted value $y$. This Function is not affected by the outliers or remove the outliers. \n",
    "[Jonathan T. Barron, A General and Adaptive Robust Loss Function. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019]\n",
    "\n",
    "This function can be used in data set may contain outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "The main purpose of training a neural network is to find suitable parameters and obtain a relatively small loss function. The process of solving this problem is called optimization. The algorithm used to solve this problem is called optimizer. Among various optimizers, we choose three of them as listed below into our account. These three are basicly improved versions based on other optimizers, thus can achieve better result.  \n",
    "\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "\n",
    "Stochastic gradient descent (SGD)  computes the gradient of the cost function with respect to the parameters $\\theta$. What's more, the whole training dataset delivers a parameter update for each training example $x^{(i)}$ and label $y^{(i)}$. It prevents redundant computations for large datasets and usually processes relatively fast. However, since SGD conducts frequent updates with high variance, it can cause the objective function to fluctuate rigorously. Also, when facing local optimal where curves are much more steeply in one dimension than in another. SGD oscillates across the area and makes slow progress. This leads to RMSprop.  [ Bottou L, Large-Scale Machine Learning with Stochastic Gradient Descent. Proceedings of COMPSTAT, 2010]\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J ( \\theta ; x^{(i)} ; y^{(i)} ) $$\n",
    "\n",
    " In the experiments above, SGD it the default optimizer we use, it can be seen that the result is very good.\n",
    "\n",
    "\n",
    "#### RMSprop\n",
    "\n",
    "For the learning rate of models, traditional optimizer either set the learning rate to a constant or adjust the learning rate based training results. All ignore the potential of the learning rate. \n",
    "\n",
    "We can consider RMSprop as an adaptation of the rprop algorithm to learning with mini-batch. This was the original motivation for developing the algorithm. It performs low learning rates on parameters related to frequently occurring features and performs high learning rates to obtain parameters related to less commonly used features. Therefore, it is very suitable for dealing with sparse data. In this way, it can greatly improve the robustness of SGD and solve the problem of the sharp drop in learning rate. It is assumed that during the $t$ iteration, each formula is as follows:\n",
    "\n",
    "[Geoffrey Hinton Neural Networks for machine learning nline course. https://www.coursera.org/learn/neural-networks/home/welcome]\n",
    "\n",
    "\n",
    "$${\n",
    "        s_{dw}= \\beta s_{dw} + (1 - \\beta)d W^2 \\\\\n",
    "        s_{db}= \\beta s_{db} + (1 - \\beta)d b^2 \\\\\n",
    "        W = W - \\alpha \\frac{dW}{\\sqrt{s_{dw}} + \\varepsilon} \\\\\n",
    "        b = b - \\alpha \\frac{db}{\\sqrt{s_{dw}} + \\varepsilon}\n",
    " }$$\n",
    "\n",
    "\n",
    "In the above formula, $s_{dw}$ and $s_{db}$ are the gradient momentum accumulated by the loss function during the first $t-1$ iterations,.Respectively,  $\\beta$ is an index of gradient accumulation. In order to prevent the denominator from being zero, a very small value $\\varepsilon$ is used for smoothing which generally take 1e-8.\n",
    "\n",
    "The RMSprop algorithm calculates the differential squared weighted average of the gradient. This method is beneficial to eliminate the direction of large swing amplitude and is used to correct the swing amplitude so that the swing amplitude in each dimension is smaller. On the other hand, it also makes the network function converge faster.\n",
    "\n",
    "We calculated the average SSIM obtained after the data set uses RMSprop with 50 epochs and displayed in the figure below. It can be seen from the figure that the data used in our training fluctuates rigorously and the result is not clear, so we do not use RMSprop in this experiment.\n",
    "\n",
    "![RMSprop.png](./RMSprop.png)\n",
    "\n",
    "#### Adaptive Moment Estimation (Adam)\n",
    "\n",
    "\n",
    "Adaptive Moment Estimation (Adam) is a method that computes adaptive learning rates for each parameter. In addition to collecting past squared gradients' exponentially decaying average $v_t$, Adam also keeps an exponentially decaying average of past gradients $m_t$ which similar to momentum. In this way, it can flat minima in the error surface. We compute the $v_t$ and $m_t$ as follows:  [Bottou, L, The Tradeoffs of Large Scale Learning.  Optimization for Machine Learning, 2012]\n",
    "\n",
    "$${\n",
    "     m_t = \\beta_1 m_{t-1} + ( 1- \\beta_1) g_t \\\\\n",
    "     v_t = \\beta_2 v_{t-1} + ( 1- \\beta_2) g_t^2\n",
    " }$$\n",
    " \n",
    "If $m_t$ and $v_t$ are initialized as zero vectors, they will be biased towards 0, so a bias correction appear. It can offset these deviations by calculating the updated $m_t$ and $v_t$ as follows:\n",
    "\n",
    "$${\n",
    "     \\hat m_t = \\frac{m_t}{1 - \\beta_1^t} \\\\\n",
    "     \\hat v_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    " }$$\n",
    "\n",
    "and last upated Adam is:\n",
    "\n",
    "$${\n",
    "        \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat v_t} + \\varepsilon} \\hat m_t\n",
    " }$$\n",
    " \n",
    "\n",
    "where $\\beta_1$ and $\\beta_2$ is often to set close to $1$\n",
    "\n",
    "Adam is generally considered to be quite robust in the choice of hyperparameters, although the learning rate sometimes needs to be modified to default.\n",
    "\n",
    "#### SGD versus Adam\n",
    "\n",
    "The following table compares the average loss as well as the average SSIM of SGD and Adam when taking five batches and 50 epochs. It can be noticed directly that Adam performs better, so we use Adam as our optimizer.\n",
    "\n",
    "|   Optimizer   | Average Loss Value  | Average SSIM | \n",
    "| ---------- | --- | --- |\n",
    "| SGD |  0.00891| 0.45697| \n",
    "| Adam |  0.00776| 0.49972| \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ref：https://ruder.io/optimizing-gradient-descent/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using true random on a larger data set with IBM new quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
