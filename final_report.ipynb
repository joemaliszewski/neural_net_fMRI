{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework for MRI reconstruction (Autumn 2019)\n",
    "\n",
    "In this tutorial, we provide the data loader to read and process the MRI data in order to ease the difficulty of training your network. By providing this, we hope you focus more on methodology development. Please feel free to change it to suit what you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction  ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL IMPORTS\n",
    "import h5py, os\n",
    "from functions import transforms as T\n",
    "from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "#cuda\n",
    "import torch.optim as optim\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu' #'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### UNET MODEL ######\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        return self.layers(input)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
    "            f'drop_prob={self.drop_prob})'\n",
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "\n",
    "    This is based on:\n",
    "        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "        for biomedical image segmentation. In International Conference on Medical image\n",
    "        computing and computer-assisted intervention, pages 234â€“241. Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "            chans (int): Number of output channels of the first convolution layer.\n",
    "            num_pool_layers (int): Number of down-sampling and up-sampling layers.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch, drop_prob)\n",
    "\n",
    "        self.up_sample_layers = nn.ModuleList()\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
    "            ch //= 2\n",
    "        self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
    "            nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = input\n",
    "        # Apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.max_pool2d(output, kernel_size=2)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Apply up-sampling layers\n",
    "        for layer in self.up_sample_layers:\n",
    "            output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            output = torch.cat([output, stack.pop()], dim=1)\n",
    "            output = layer(output)\n",
    "        return self.conv2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-defined ultily functions used in creating the neural net\n",
    "\n",
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')\n",
    "\n",
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "#     A = cropped_img_und.squeeze().detach().cpu()\n",
    "#     C = cropped_gt.squeeze().squeeze().detach().cpu()\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "    \n",
    "    volume_image_abs = T.complex_abs(img_gt) \n",
    "    cropped_gt = T.center_crop(volume_image_abs, [320, 320])\n",
    "    cropped_gt = cropped_gt\n",
    "        \n",
    "    volume_image_abs = T.complex_abs(img_und) \n",
    "    cropped_img_und = T.center_crop(volume_image_abs, [320, 320])\n",
    "    cropped_img_und = cropped_img_und\n",
    "        \n",
    "    return cropped_gt,cropped_img_und, norm\n",
    "  #return img_gt.squeeze(0), img_und.squeeze(0), rawdata_und.squeeze(0), masks.squeeze(0), norm\n",
    "\n",
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list\n",
    "        self.acceleration = acceleration\n",
    "        self.center_fraction = center_fraction\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)\n",
    "    \n",
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "\n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "\n",
    "        which_data_path = data_path[i]\n",
    "\n",
    "        for fname in sorted(os.listdir(which_data_path)):\n",
    "\n",
    "            subject_data_path = os.path.join(which_data_path, fname)\n",
    "\n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "\n",
    "            with h5py.File(subject_data_path, 'r') as data:\n",
    "                num_slice = data['kspace'].shape[0]\n",
    "\n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "\n",
    "    return data_list  \n",
    "   \n",
    "    \n",
    "from skimage.measure import compare_ssim  \n",
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    return compare_ssim(\n",
    "        gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max()\n",
    "    )  \n",
    "\n",
    "\n",
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model\n",
    "model = UnetModel(\n",
    "    in_chans = 1,\n",
    "    out_chans = 1,\n",
    "    chans = 32,\n",
    "    num_pool_layers = 4,\n",
    "    drop_prob = 0 ).to(device) # FirstModel().to(device)\n",
    "\n",
    "# # we can also inspect its parameters\n",
    "# print(\"Before training: \\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Set initial path for the fullset of training data\n",
    "# file_path = '/data/local/NC2019MRI/train'\n",
    "\n",
    "# # Shuffle sets, and split train_index into train and validation 80:20 respectively \n",
    "# numfiles_all = len(os.listdir(file_path))\n",
    "# print (numfiles_all)\n",
    "# indx = np.arange(numfiles_all)\n",
    "# np.random.shuffle(indx)\n",
    "\n",
    "# split_80_20 = 0.8 * numfiles_all\n",
    "# split_80_20 = int(split_80_20)\n",
    "# print(split_80_20)\n",
    "\n",
    "# np.random.seed(42)\n",
    "\n",
    "# train_inx = indx[:split_80_20]\n",
    "# val_inx = indx[split_80_20:]\n",
    "\n",
    "# print(\"train_inx\",train_inx)\n",
    "# print(\"val_inx\",val_inx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     train_data_list = {}\n",
    "#     train_data_list['val']= [0] * len(val_inx)\n",
    "#     train_data_list['train'] = [0] * len(train_inx)\n",
    "#     count = 0  \n",
    "    \n",
    "#     for fname in sorted(os.listdir(file_path)): \n",
    "#         subject_path = os.path.join(file_path, fname)\n",
    "#         with h5py.File(subject_path,  \"r\") as hf:\n",
    "#              total_num_slices = hf['kspace'].shape[0]\n",
    "\n",
    "                \n",
    "#         for i in range(len(train_inx)):\n",
    "#             if (train_inx[i] == count):\n",
    "#                 train_data_list['train'][i] = (file_path+ \"/\" +fname, fname, total_num_slices)  \n",
    "#                 break\n",
    "                \n",
    "#         for k in range(len(val_inx)):\n",
    "#             if (val_inx[k] == count):\n",
    "#                 train_data_list['val'][k] = (file_path+ \"/\"+ fname, fname, total_num_slices)\n",
    "#                 break\n",
    "#         count = count +1\n",
    "\n",
    "            \n",
    "#     train_data_final ={}         \n",
    "#     train_data_final['train'] = []  \n",
    "#     train_data_final['val'] = []  \n",
    "           \n",
    "#     for i in range (len(train_data_list['train'])):\n",
    "#         for slice in range (5,train_data_list['train'][i][2]):\n",
    "#             train_data_final['train'].append((train_data_list['train'][i][1], train_data_list['train'][i][0], (slice)))\n",
    "        \n",
    "\n",
    "#     for i in range (len(train_data_list['val'])):\n",
    "#         for slice in range (5,train_data_list['val'][i][2]):\n",
    "#             train_data_final['val'].append((train_data_list['val'][i][1], train_data_list['val'][i][0], slice))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"VALIDATION SET\")\n",
    "# valcount = 0\n",
    "# for i in range (len(train_data_final['val'])):\n",
    "#     print(\" count : \",valcount,\"  \", train_data_final['val'][i])\n",
    "#     valcount = valcount + 1\n",
    "    \n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "\n",
    "# train_count = 0    \n",
    "# print(\"TRAIN SET\")\n",
    "# for i in range (len(train_data_final['train'])):\n",
    "#     print(\" count : \",train_count,\"  \", train_data_final['train'][i])\n",
    "#     train_count = train_count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_path_train = '/data/local/NC2019MRI/train'\n",
    "    data_path_val = '/data/local/NC2019MRI/train'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0428293723e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMRIDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceleration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcen_fract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_final' is not defined"
     ]
    }
   ],
   "source": [
    "######loads_train_data #######\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    acc = 8\n",
    "    cen_fract = 0.04\n",
    "    seed = False # random masks for each slice \n",
    "    num_workers = 12 \n",
    "    \n",
    "    \n",
    "    #\n",
    "    train_dataset = MRIDataset(train_data_final['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=5, num_workers=num_workers) \n",
    "    \n",
    "    validation_dataset = MRIDataset(train_data_final['val'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    validation_loader = DataLoader(validation_dataset, shuffle=True, batch_size=5, num_workers=num_workers)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Unet model below created by MIT, and was used in the assignment as a platform to build the neural network. https://github.com/facebookresearch/fastMRI.git"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "During the iterative cycle of training, the model may begin to overfit the model, rendering it ineffective to \n",
    "\n",
    "The a validation set is created in order to ensure the model is not \"over fitting\" the training data. An "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELOLOOO\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73a8e88d6667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# # We use mean square error (MSELoss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Optimisers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#set training\n",
    "%matplotlib inline \n",
    "print(\"HELOLOOO\")\n",
    "# set learning rate\n",
    "\n",
    "#lr = 1e-4\n",
    "# lr = 1e-3\n",
    "# lr = 1e-2\n",
    "lr = 1e-1\n",
    "\n",
    "#set number of epoches, i.e., number of times we iterate through the training set\n",
    "epoches = 50\n",
    "\n",
    "# # We use mean square error (MSELoss)\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# Optimisers\n",
    "#optimiser = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "optimiser = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Lists for plotting val/train SSIM/Loss/prEpoch\n",
    "train_av_epoch_ssim_list = []\n",
    "train_av_epoch_loss_list = []\n",
    "\n",
    "val_av_epoch_ssim_list = []\n",
    "val_av_epoch_loss_list = []\n",
    "\n",
    "epoch_count = 0\n",
    "\n",
    "#Model training\n",
    "for epoch in range(epoches):\n",
    "   \n",
    "    model.train()\n",
    "    \n",
    "    train_total_loss = 0\n",
    "    train_total_ssim = 0\n",
    "    train_iterations= 0\n",
    "    \n",
    "    val_total_loss = 0\n",
    "    val_total_ssim = 0\n",
    "    val_iterations= 0\n",
    "    \n",
    "    #Training\n",
    "    for data in train_loader:\n",
    "\n",
    "        # set the model to training mode\n",
    "        img_gt, img_und, _ = data\n",
    "        \n",
    "        #Reconstruction/prediction from undersampled data\n",
    "        img_gt = img_gt.to(device) \n",
    "        img_und.to(device) \n",
    "        optimiser.zero_grad()\n",
    "        print(train_iterations, '!!!!!size:',img_und.size(), img_gt.size())\n",
    "        y_pred = model(img_und.to(device))\n",
    "        \n",
    "                #visualise \n",
    "        # 0 = UNDERSAMPLED. 1 = PREDICTION. 2 = GROUND_TRUTH\n",
    "        #if train_iterations % 10 == 1:\n",
    "        A = img_und.squeeze().squeeze().numpy()[0:1,:,:]\n",
    "        B = y_pred.squeeze().squeeze().squeeze(0).detach().cpu()\n",
    "        \n",
    "        B = y_pred.squeeze().data.cpu().numpy()\n",
    "        B = B[0:1, :, :]\n",
    "        #print(B.shape)\n",
    "        \n",
    "        C = img_gt.squeeze().squeeze().squeeze(0).cpu().numpy()[0:1,:,:]\n",
    "        all_imgs = np.concatenate([A,B,C], axis=0)\n",
    "\n",
    "        #Visualise\n",
    "        #show_slices(all_imgs, [0,1,2], cmap='gray')\n",
    "        #plt.pause(1)\n",
    "\n",
    "        \n",
    "        #calculate the loss from training data\n",
    "        loss = loss_fn(img_gt.to(device), y_pred)\n",
    "        loss.backward() \n",
    "        optimiser.step()\n",
    "        \n",
    "        #calculate total loss for epoch to generate average loss\n",
    "        train_total_loss = train_total_loss + loss.item()\n",
    "        \n",
    "        # calculate total ssim value for epoch to generate average ssim\n",
    "        ssim_value = ssim(C,B)\n",
    "        train_total_ssim = train_total_ssim + ssim_value\n",
    "     \n",
    "\n",
    "        #count\n",
    "        train_iterations = train_iterations +1\n",
    "        \n",
    "        \n",
    "    train_av_ssim = train_total_ssim/train_iterations\n",
    "    train_av_loss = train_total_loss/train_iterations\n",
    "    \n",
    "    train_av_epoch_ssim_list.append(train_av_ssim)\n",
    "    train_av_epoch_loss_list.append(train_av_loss)\n",
    "    \n",
    "    \n",
    "#     #Validation \n",
    "#     with torch.no_grad():\n",
    "#         #set to evaluation mode\n",
    "#         model.eval()\n",
    "#         for data in validation_loader:\n",
    "\n",
    "#             #from data loader\n",
    "#             img_gt, img_und, _ = data\n",
    "            \n",
    "#             #Reconstruction/prediction from undersampled data\n",
    "#             img_gt = img_gt.to(device) \n",
    "#             img_und.to(device) \n",
    "#             optimiser.zero_grad()\n",
    "#             print('!!!!!size:',img_und.size(), img_gt.size())\n",
    "#             y_pred = model(img_und.to(device))\n",
    "            \n",
    "#             A = img_und.squeeze().squeeze().numpy()[0:1,:,:]\n",
    "#             B = y_pred.squeeze().squeeze().squeeze(0).detach().cpu()\n",
    "        \n",
    "#             B = y_pred.squeeze().data.cpu().numpy()\n",
    "#             B = B[0:1, :, :]\n",
    "            \n",
    "#         #print(B.shape)\n",
    "        \n",
    "#             C = img_gt.squeeze().squeeze().squeeze(0).cpu().numpy()[0:1,:,:]\n",
    "#             all_imgs = np.concatenate([A,B,C], axis=0)\n",
    "            \n",
    "            \n",
    "#              #calculate the loss from validation data\n",
    "#             val_loss = loss_fn(img_gt.to(device), y_pred)\n",
    "#             optimiser.step()\n",
    "            \n",
    "#             #calculate total loss for epoch to generate average loss\n",
    "#             val_total_loss = val_total_loss + loss.item()\n",
    "        \n",
    "        \n",
    "# #             A = img_und.unsqueeze(1).n\n",
    "# #             B = y_pred.squeeze().squeeze().detach().cpu().numpy()\n",
    "# #             C = img_gt.squeeze().squeeze().cpu().numpy()\n",
    "# #             #print(A.shape, B.shape, C.shape)\n",
    "            \n",
    "#             #all_imgs = torch.stack([A.squeeze(),B,C], dim=0)\n",
    "#             #print(\"1\")\n",
    "#            # show_slices(all_imgs, [0,1,2], cmap='gray')\n",
    "#             #plt.pause(1)\n",
    "#             #print(\"2\")\n",
    "#             #calculate total ssim value for epoch to generate average ssim\n",
    "#             ssim_value = ssim(C,B)\n",
    "#             val_total_ssim = val_total_ssim + ssim_value\n",
    "            \n",
    "#             #count\n",
    "#             val_iterations = val_iterations + 1\n",
    "            \n",
    "#     val_av_ssim = val_total_ssim/val_iterations\n",
    "#     val_av_loss = val_total_loss/val_iterations\n",
    "    \n",
    "#     val_av_epoch_ssim_list.append(val_av_ssim)\n",
    "#     val_av_epoch_loss_list.append(val_av_loss)\n",
    "    \n",
    "#     epoch_count = epoch_count + 1\n",
    "    print(\"epoch_count \", epoch_count)\n",
    "\n",
    "print(\"epoch: \", epoch_count,\"train_av_epoch_ssim_list :\", train_av_epoch_ssim_list)\n",
    "print(\"epoch: \", epoch_count,\"train_av_epoch_loss_list :\", train_av_epoch_loss_list)\n",
    "#print(\"epoch: \", epoch_count,\"val_av_epoch_ssim_list :\", val_av_epoch_ssim_list)\n",
    "#print(\"epoch: \", epoch_count,\"val_av_epoch_loss_list :\", val_av_epoch_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION VS TRAINING SSIM COMPARISON\n",
    "plt.plot(range(len(train_av_epoch_ssim_list)), train_av_epoch_ssim_list,'r', label = \"Av Train SSIM\")\n",
    "plt.plot(range(len(val_av_epoch_ssim_list)), val_av_epoch_ssim_list,'b', label = \"Av Val SSIM\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Av SSIM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION VS TRAINING LOSS COMPARISON\n",
    "plt.plot(range(len(train_av_epoch_loss_list)), train_av_epoch_loss_list,'r', label = \"Av Training loss\")\n",
    "plt.plot(range(len(val_av_epoch_loss_list)), val_av_epoch_loss_list,'b', label = \"Av Val loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"unet_model_save_50ep_sgd_le1_b5_L1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = train_av_epoch_loss_list\n",
    "#x = val_av_epoch_loss_list\n",
    "#x = train_av_epoch_ssim_list\n",
    "x = val_av_epoch_ssim_list\n",
    "\n",
    "total = 0\n",
    "for i in range(len(x)):\n",
    "    total = total +x[i]\n",
    "    av = total/(len(x))\n",
    "print(av)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The MRI data\n",
    "\n",
    "How it generated\n",
    "\n",
    "Ksapce\n",
    "\n",
    "How converted to a normal image\n",
    "\n",
    "task and aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design\n",
    "\n",
    "## U-net\n",
    "\n",
    "![unet.png](./unet.png)\n",
    "In 2015, OlafRonneberger and others proposed a U-net network structure. The U-net network is a semantic segmentation network based on FCN, which is suitable for medical image segmentation.\n",
    "\n",
    "\n",
    "The entire U-Net network structure is shown in the figure above, similar to a large U letter: first convolution + Pooling down-sampling; then deconvolution for up-sampling, low-level feature map before the crop, and fusion; then up-sampling again. Repeat this process until you get a feature map with an output of 388x388x2, and finally, get the output segment map through soft-max. Overall, it is very similar to the FCN idea. (If not necessary, delete them) Unet's original intention is to solve the problems of biomedical images. Since the effect is really good, it has been widely used in various directions of semantic segmentation, such as satellite image segmentation and industrial defect detection.\n",
    "[Ronneberger O, Fischer P, Brox T, U-net: Convolutional networks for biomedical image segmentation. International Conference on Medical image computing and computer-assisted intervention, 2015 ]\n",
    "\n",
    "[Wenjun Y, Yuanyuan W, Shengjia G, The Domain Shift Problem of Medical Image Segmentation and Vendor-Adaptation by Unet-GAN. International Conference on Medical Image Computing and Computer-Assisted Intervention, 2019 ]\n",
    "\n",
    "### Advantages\n",
    "â€¢ Support for training models with a small amount of data \n",
    "\n",
    "â€¢ Get higher segmentation accuracy by classifying each pixel \n",
    "\n",
    "â€¢ Fast segmentation with trained models \n",
    "\n",
    "\n",
    "## Gan\n",
    "\n",
    "GAN is composed of a generator and a discriminator. The purpose of the generator is to generate fake targets in an attempt to completely deceive the discriminator. The discriminator improves its discrimination ability by learning the true target and the false target, so as not to let the false target fool itself. The two evolved and played against each other. One side evolved and the other lost. Finally, the evolution stopped until the false target was very similar to the true target. The main flow is similar to the figure above. First of all, there is a generation generator that can generate some very poor pictures, and then there is a generation discriminator that can accurately classify the generated picture with the real picture, and then repeat the above action(If not necessary, delete them) Compared with all other models, GAN can produce clearer and true samples. GAN uses an unsupervised learning method for training, which can be widely used in the fields of unsupervised learning and semi-supervised learning. However, because of the unsupervised GAN, in the generation process, it will generate some weird pictures according to its own wishes for a long time. Whatâ€™s worse, this picture can still get a high score.\n",
    "\n",
    "[ Sebastian N, Botond C, Ryota T, f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization.  Advances in Neural Information Processing Systems, 2016 ]\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this experiment, we chose U-net as our training model due to we have seen that U-net has achieved good results in this field in many previous studies, while GAN has fewer applications in medical imaging. Also, U-net has a fast processing speed and a higher segmentation accuracy which is beneficial to our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "## Batch \n",
    "\n",
    "Batch is the number of samples selected for a single training session. Its size affects the degree and speed of optimization of the model. At the same time, it directly affects the GPU memory usage. When chose the best batch size, it can improve memory utilization through parallelization by enabling GPU to run at full capacity to improve training speed. Also, the number of iterations of a single epoch is reduced and the adjustment of parameters is slow, which more epochs are required to achieve the same recognition accuracy. Most importantly, the proper batch will improve the gradient descent.\n",
    "[ Alfredo C, Adam P, Eugenio C, An Analysis of Deep Neural Network Models for Practical Applications. arXiv preprint arXiv:1605.07678, 2016]\n",
    "\n",
    "We calculated the average loss function and SSIM of both training data and validation data set with the batch from 3 to 6 when epochs is 0 to 50. We can easily conclude from the table that the SSIM and is better when the Batch is 5 as we list the result as below.\n",
    "\n",
    "|    Batch Size    | Average Training Data Loss   |    Average Validation Data Loss    | Average Training Data SSIM |    Average Validation Data SSIM    |\n",
    "| ---------- | --- | --- | --- | --- |\n",
    "| 3 |  0.00816| 0.00859| 0.47535 | 0.50365|\n",
    "| 4 |  0.00808| 0.00784| 0.48208 | 0.45985|\n",
    "| 5 |  0.00891| 0.00913| 0.45697 | 0.53715|\n",
    "| 6 |  0.00872| 0.00890| 0.46395 | 0.49930|\n",
    "\n",
    "When the batch is 5, the obtained data curve is shown below. Both the average SSIM and the SSIM at 50 epochs of the training data set is around 0.46. Since the SSIM of validation data set is more vibrate and with an average of 0.53 but can reach about 0.57 at 50 epochs, which is significant. \n",
    "\n",
    "As for the training data loss function, statistics tend to descend steadily. Although validation data loss contains a lot of noise, the overall trend is also decreasing.\n",
    "\n",
    "![Batch5Loss.png](./Batch5Loss.png)\n",
    "![Batch5SSIM.png](./Batch5SSIM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "\n",
    "The learning rate determines how far the weights move in the gradient direction in a batch. Choosing a suitable learning rate requires constant experimentation and adjustment.\n",
    "\n",
    "When the learning rate is very small,  the training will become reliable, that is, the gradient will gradually approach the minimum value. The calculated loss will become smaller as well as the cost is that the training time will take longer. When the learning rate is very large, the training will ignore the minimum value, showing that the loss value continuously fluctuates. In the most severe cases, it may never reach the minimum value, or even jump out of this range and fall into another sinking area. [ Robert A.Jacobs Increased rates of convergence through learning rate adaptation. Neural Networks, 1988]\n",
    "\n",
    "We calculated the average loss function and SSIM of training data set with the batch size of 5 and epochs is 0 to 50. The following figures are examples of the average loss of different learning rate. The average loss drops rapidly around the first five epochs, and then it tends to decrease steadily. When enhancing the learning rate from 1e-1 to 1e-5, the loss in of the same epoch increases, and its overall trend remains unchanged. \n",
    "![LR1Loss.png](./LR1Loss.png)\n",
    "![LR4Loss.png](./LR4Loss.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The following are the results of average SSIM. It can be seen from the figures that average SSIM increased rapidly around the first five epochs, followed by an upward trend, and accompanied by fluctuations of a certain intensity. When learning rate increasing, the subsequent fluctuation of the SSIM value weakened, and the results obtained gradually became more stable.\n",
    "![LR1SSIM.png](./LR1SSIM.png)\n",
    "![LR4SSIM.png](./LR4SSIM.png)\n",
    "\n",
    "\n",
    "The following table is a summary of the results of the above. In the obtained results, the learning rate of 1e-1 to le-4 all conform to the above analysis, but the hyperparameter of 1e-5 do not correspond to the above rule. This is because after the learning rate increases, if epoch keeps at the same value, then the number of samples received is not enough to reflect the overall changing trend of average loss and average SSIM.\n",
    "\n",
    "|    Learning Rate    | Average Training Data Loss   | Average Training Data SSIM |\n",
    "| ---------- | --- | --- |\n",
    "| 1e-1 |  0.00825| 0.47871| \n",
    "| 1e-2 |  0.00808| 0.48208| \n",
    "| 1e-3 |  0.01674| 0.35583|\n",
    "| 1e-4 |  0.03098| 0.22719|\n",
    "| 1e-5 |  0.01797| 0.10929|\n",
    "\n",
    "![LR5Loss.png](./LR5Loss.png)\n",
    "![LR5SSIM.png](./LR5SSIM.png)\n",
    "\n",
    "The above analysis all based on 4-folders, we calculated with 8 times acceleration rate. We change the epoch to 120 and the learning rate is le-1 to achieve a better result. The leaning of the two values is almost the same as that in the case of 4-folders, except that the fluctuation of SSIM is slightly more obvious due to the increase of epoch. From the table below, its average loss is more miniature and the average SSIM is higher.\n",
    "\n",
    "|    Acceleration Rate    | Average Training Data Loss   | Average Training Data SSIM |\n",
    "| ---------- | --- | --- |\n",
    "| 4 times |  0.00825| 0.47871| \n",
    "| 8 times |  0.00437| 0.59028| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    " The predicted value obtained after using the model for training in the neural network needs to be compared with the ground truth so that the model can self-corrects until the difference becomes really small. With different loss functions, the influence on the model will differ too. We need to choose the most suitable function to get the most ideal model. We decided to use L1 as the orimary loss functions as: \n",
    "\n",
    "#### L1 Loss\n",
    "\n",
    "$${\n",
    "  loss(x,y)= \\sum_{i=1}^{n} (x-y)^2 \n",
    " }$$\n",
    "\n",
    "L1 Loss Function is used to minimize the error which is the sum of the all the absolute differences between the true value $x$ and the predicted value $y$. This Function is not affected by the outliers or remove the outliers. \n",
    "[Jonathan T. Barron, A General and Adaptive Robust Loss Function. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019]\n",
    "\n",
    "This function can be used in data set may contain outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "The main purpose of training a neural network is to find suitable parameters and obtain a relatively small loss function. The process of solving this problem is called optimization. The algorithm used to solve this problem is called optimizer. Among various optimizers, we choose three of them as listed below into our account. These three are basicly improved versions based on other optimizers, thus can achieve better result.  \n",
    "\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "\n",
    "Stochastic gradient descent (SGD)  computes the gradient of the cost function with respect to the parameters $\\theta$. What's more, the whole training dataset delivers a parameter update for each training example $x^{(i)}$ and label $y^{(i)}$. It prevents redundant computations for large datasets and usually processes relatively fast. However, since SGD conducts frequent updates with high variance, it can cause the objective function to fluctuate rigorously. Also, when facing local optimal where curves are much more steeply in one dimension than in another. SGD oscillates across the area and makes slow progress. This leads to RMSprop.  [ Bottou L, Large-Scale Machine Learning with Stochastic Gradient Descent. Proceedings of COMPSTAT, 2010]\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J ( \\theta ; x^{(i)} ; y^{(i)} ) $$\n",
    "\n",
    " In the experiments above, SGD it the default optimizer we use, it can be seen that the result is very good.\n",
    "\n",
    "\n",
    "#### RMSprop\n",
    "\n",
    "For the learning rate of models, traditional optimizer either set the learning rate to a constant or adjust the learning rate based training results. All ignore the potential of the learning rate. \n",
    "\n",
    "We can consider RMSprop as an adaptation of the rprop algorithm to learning with mini-batch. This was the original motivation for developing the algorithm. It performs low learning rates on parameters related to frequently occurring features and performs high learning rates to obtain parameters related to less commonly used features. Therefore, it is very suitable for dealing with sparse data. In this way, it can greatly improve the robustness of SGD and solve the problem of the sharp drop in learning rate. It is assumed that during the $t$ iteration, each formula is as follows:\n",
    "\n",
    "[Geoffrey Hinton Neural Networks for machine learning nline course. https://www.coursera.org/learn/neural-networks/home/welcome]\n",
    "\n",
    "\n",
    "$${\n",
    "        s_{dw}= \\beta s_{dw} + (1 - \\beta)d W^2 \\\\\n",
    "        s_{db}= \\beta s_{db} + (1 - \\beta)d b^2 \\\\\n",
    "        W = W - \\alpha \\frac{dW}{\\sqrt{s_{dw}} + \\varepsilon} \\\\\n",
    "        b = b - \\alpha \\frac{db}{\\sqrt{s_{dw}} + \\varepsilon}\n",
    " }$$\n",
    "\n",
    "\n",
    "In the above formula, $s_{dw}$ and $s_{db}$ are the gradient momentum accumulated by the loss function during the first $t-1$ iterations,.Respectively,  $\\beta$ is an index of gradient accumulation. In order to prevent the denominator from being zero, a very small value $\\varepsilon$ is used for smoothing which generally take 1e-8.\n",
    "\n",
    "The RMSprop algorithm calculates the differential squared weighted average of the gradient. This method is beneficial to eliminate the direction of large swing amplitude and is used to correct the swing amplitude so that the swing amplitude in each dimension is smaller. On the other hand, it also makes the network function converge faster.\n",
    "\n",
    "We calculated the average SSIM obtained after the data set uses RMSprop with 50 epochs and displayed in the figure below. It can be seen from the figure that the data used in our training fluctuates rigorously and the result is not clear, so we do not use RMSprop in this experiment.\n",
    "\n",
    "![RMSprop.png](./RMSprop.png)\n",
    "\n",
    "#### Adaptive Moment Estimation (Adam)\n",
    "\n",
    "\n",
    "Adaptive Moment Estimation (Adam) is a method that computes adaptive learning rates for each parameter. In addition to collecting past squared gradients' exponentially decaying average $v_t$, Adam also keeps an exponentially decaying average of past gradients $m_t$ which similar to momentum. In this way, it can flat minima in the error surface. We compute the $v_t$ and $m_t$ as follows:  [Bottou, L, The Tradeoffs of Large Scale Learning.  Optimization for Machine Learning, 2012]\n",
    "\n",
    "$${\n",
    "     m_t = \\beta_1 m_{t-1} + ( 1- \\beta_1) g_t \\\\\n",
    "     v_t = \\beta_2 v_{t-1} + ( 1- \\beta_2) g_t^2\n",
    " }$$\n",
    " \n",
    "If $m_t$ and $v_t$ are initialized as zero vectors, they will be biased towards 0, so a bias correction appear. It can offset these deviations by calculating the updated $m_t$ and $v_t$ as follows:\n",
    "\n",
    "$${\n",
    "     \\hat m_t = \\frac{m_t}{1 - \\beta_1^t} \\\\\n",
    "     \\hat v_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    " }$$\n",
    "\n",
    "and last upated Adam is:\n",
    "\n",
    "$${\n",
    "        \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat v_t} + \\varepsilon} \\hat m_t\n",
    " }$$\n",
    " \n",
    "\n",
    "where $\\beta_1$ and $\\beta_2$ is often to set close to $1$\n",
    "\n",
    "Adam is generally considered to be quite robust in the choice of hyperparameters, although the learning rate sometimes needs to be modified to default.\n",
    "\n",
    "#### SGD versus Adam\n",
    "\n",
    "The following table compares the average loss as well as the average SSIM of SGD and Adam when taking five batches and 50 epochs. It can be noticed directly that Adam performs better, so we use Adam as our optimizer.\n",
    "\n",
    "|   Optimizer   | Average Loss   | Average SSIM | \n",
    "| ---------- | --- | --- |\n",
    "| SGD |  0.00891| 0.45697| \n",
    "| Adam |  0.00776| 0.49972| \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Refï¼šhttps://ruder.io/optimizing-gradient-descent/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
